# -*- coding: utf-8 -*-
"""train-yolo11-object-detection-on-custom-dataset.ipynb adlÄ± not defterinin kopyasÄ±

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14aaloujBWtbzDzJomt4posURSEc6pfhv

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Train YOLO11 Object Detection on a Custom Dataset

---

[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)

YOLO11 builds on the advancements introduced in YOLOv9 and YOLOv10 earlier this year, incorporating improved architectural designs, enhanced feature extraction techniques, and optimized training methods.

YOLO11m achieves a higher mean mAP score on the COCO dataset while using 22% fewer parameters than YOLOv8m, making it computationally lighter without sacrificing performance.

YOLOv11 is available in 5 different sizes, ranging from `2.6M` to `56.9M` parameters, and capable of achieving from `39.5` to `54.7` mAP on the COCO dataset.

## Setup

### Configure API keys

To fine-tune YOLO11, you need to provide your Roboflow API key. Follow these steps:

- Go to your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.
- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘). Store Roboflow API Key under the name `ROBOFLOW_API_KEY`.

### Before you start

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`.
"""



"""**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."""

import os
HOME = os.getcwd()
print(HOME)
import subprocess

"""## Install YOLO11 via Ultralytics"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install "ultralytics<=8.3.40" supervision roboflow
# prevent ultralytics from tracking your activity

import ultralytics
ultralytics.checks()

"""## Inference with model pre-trained on COCO dataset

### CLI

**NOTE:** CLI requires no customization or Python code. You can simply run all tasks from the terminal with the yolo command.
"""

!yolo task=detect mode=predict model=yolo11n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True

"""**NOTE:** Result annotated image got saved in `{HOME}/runs/detect/predict/`. Let's display it.

### SDK

**NOTE:** YOLO's Python interface allows for seamless integration into your Python projects, making it easy to load, run, and process the model's output.
"""

from ultralytics import YOLO
from PIL import Image
import requests

model = YOLO('yolo11n.pt')
image = Image.open(requests.get('https://media.roboflow.com/notebooks/examples/dog.jpeg', stream=True).raw)
result = model.predict(image, conf=0.25)[0]

"""**NOTE:** The obtained `result` object stores information about the location, classes, and confidence levels of the detected objects."""

result.boxes.xyxy

result.boxes.conf

result.boxes.cls

"""**NOTE:** YOLO11 can be easily integrated with `supervision` using the familiar `from_ultralytics` connector."""

import supervision as sv

detections = sv.Detections.from_ultralytics(result)

box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator(text_color=sv.Color.BLACK)

annotated_image = image.copy()
annotated_image = box_annotator.annotate(annotated_image, detections=detections)
annotated_image = label_annotator.annotate(annotated_image, detections=detections)

sv.plot_image(annotated_image, size=(10, 10))

"""## Fine-tune YOLO11 on custom dataset

**NOTE:** When training YOLOv11, make sure your data is located in `datasets`. If you'd like to change the default location of the data you want to use for fine-tuning, you can do so through Ultralytics' `settings.json`. In this tutorial, we will use one of the [datasets](https://universe.roboflow.com/liangdianzhong/-qvdww) available on [Roboflow Universe](https://universe.roboflow.com/). When downloading, make sure to select the `yolov11` export format.
"""

!pip install roboflow

# Commented out IPython magic to ensure Python compatibility.
!mkdir {HOME}/datasets
# %cd {HOME}/datasets

from google.colab import userdata
from roboflow import Roboflow



from roboflow import Roboflow
rf = Roboflow(api_key="6mxOI9eDNcGam1mTqmpN")
project = rf.workspace("ebrudetection").project("category-prediction-kw3wc")
version = project.version(1)
dataset = version.download("yolov11")

"""## Custom Training"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

!yolo task=detect mode=train model=yolo11s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True

"""**NOTE:** The results of the completed training are saved in `{HOME}/runs/detect/train/`. Let's examine them."""

!ls {HOME}/runs/detect/train/

from IPython.display import Image as IPyImage

IPyImage(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)

from IPython.display import Image as IPyImage

IPyImage(filename=f'{HOME}/runs/detect/train/results.png', width=600)

from google.colab import drive
drive.mount('/content/drive')

from IPython.display import Image as IPyImage

IPyImage(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)

"""## Validate fine-tuned model"""

!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml

"""## Inference with custom model"""

!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source=/content/drive/MyDrive/Prediction/output_images_video_1_sn_gecisli_v2_.mp4 save=True

import os
import glob

latest_folder = max(glob.glob(f'{HOME}/runs/detect/predict*/'), key=os.path.getmtime)
input_video_path = os.path.join(latest_folder, 'output_images_video_1_sn_gecisli_v2_.avi')
output_video_path = os.path.join(latest_folder, 'output_video.mp4')

# FFmpeg komutunu bir dize (string) olarak hazÄ±rlayÄ±n
command = f"ffmpeg -i {input_video_path} -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k {output_video_path}"

# Komutu Python'Ä±n subprocess modÃ¼lÃ¼ aracÄ±lÄ±ÄŸÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n
try:
    subprocess.run(command, shell=True, check=True)
    # Komut baÅŸarÄ±lÄ±ysa devam edin
except subprocess.CalledProcessError as e:
    # Komut baÅŸarÄ±sÄ±z olursa Streamlit'te hata gÃ¶sterin
    st.error(f"Video dÃ¶nÃ¼ÅŸtÃ¼rme (ffmpeg) sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
    # Ä°steÄŸe baÄŸlÄ± olarak uygulamanÄ±n durmasÄ±nÄ± saÄŸlayabilirsiniz
    # st.stop()ffmpeg -i {input_video_path} -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k {output_video_path}

"""**NOTE:** Let's take a look at few results."""

import glob
import os
from IPython.display import Image as IPyImage, display

latest_folder = max(glob.glob(f'{HOME}/runs/detect/predict*/'), key=os.path.getmtime)
for img in glob.glob(f'{latest_folder}/*.jpg')[:3]:
    display(IPyImage(filename=img, width=600))
    print("\n")

"""## Deploy model on Roboflow

Once you have finished training your YOLOv11 model, youâ€™ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.

The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv11 weights.
"""

project.version(dataset.version).deploy(model_type="yolov11", model_path=f"{HOME}/runs/detect/train/")

!pip install inference

import os, random, cv2
import supervision as sv
import IPython
import inference

model_id = project.id.split("/")[1] + "/" + dataset.version
model = inference.get_model(model_id, userdata.get('ROBOFLOW_API_KEY'))

# Location of test set images
test_set_loc = dataset.location + "/test/images/"
test_images = os.listdir(test_set_loc)

# Run inference on 4 random test images, or fewer if fewer images are available
for img_name in random.sample(test_images, min(4, len(test_images))):
    print("Running inference on " + img_name)

    # Load image
    image = cv2.imread(os.path.join(test_set_loc, img_name))

    # Perform inference
    results = model.infer(image, confidence=0.4, overlap=30)[0]
    detections = sv.Detections.from_inference(results)

    # Annotate boxes and labels
    box_annotator = sv.BoxAnnotator()
    label_annotator = sv.LabelAnnotator()
    annotated_image = box_annotator.annotate(scene=image, detections=detections)
    annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)

    # Display annotated image
    _, ret = cv2.imencode('.jpg', annotated_image)
    i = IPython.display.Image(data=ret)
    IPython.display.display(i)

"""## ðŸ† Congratulations

### Learning Resources

Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:

- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.
- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.
- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.
- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.

### Convert data formats

Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.

### Connect computer vision to your project logic

[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections.
"""

# Streamlit ve video iÅŸleme kÃ¼tÃ¼phaneleri
!pip install streamlit opencv-python numpy

# Ultralytics genellikle yÃ¼klÃ¼ olsa da, kontrol amaÃ§lÄ± tekrar yazÄ±labilir
!pip install ultralytics

# Streamlit uygulamasÄ±nÄ± dÄ±ÅŸarÄ±ya aÃ§mak iÃ§in pyngrok
!pip install pyngrok

# --- LÃœTFEN SADECE AÅžAÄžIDAKÄ° SATIRI DÃœZENLEYÄ°N ---
# EÄŸer 'best.pt' dosyanÄ±z doÄŸrudan Colab'in kÃ¶k dizinindeyse (en yaygÄ±n durum)
MODEL_PATH = "/content/runs/detect/train/weights/best.pt"

# EÄŸer daha derin bir klasÃ¶rdeyse, o yolu yazÄ±n.
# Ã–rneÄŸin: MODEL_PATH = "runs/detect/train/weights/best.pt"
# ------------------------------------------------

# Model dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edelim
import os
if os.path.exists("/content/runs/detect/train/weights/best.pt"):
    print(f"âœ… BaÅŸarÄ±lÄ±! Model aÄŸÄ±rlÄ±klarÄ± bu yolda bulundu: {"/content/runs/detect/train/weights/best.pt"}")
else:
    print(f"âŒ Hata: Model aÄŸÄ±rlÄ±k dosyasÄ± {"/content/runs/detect/train/weights/best.pt"} yolunda bulunamadÄ±. LÃ¼tfen yolu kontrol edin.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import cv2
# import numpy as np
# import tempfile
# import os
# from ultralytics import YOLO
# 
# # Model yolunu ortam deÄŸiÅŸkeninden alÄ±yoruz
# MODEL_PATH = os.environ.get("YOLO_MODEL_PATH", "best.pt")
# 
# # Model bir kez yÃ¼klenir ve Ã¶nbelleÄŸe alÄ±nÄ±r
# @st.cache_resource
# def load_yolo_model(path):
#     try:
#         model = YOLO(path)
#         return model
#     except Exception as e:
#         st.error(f"YOLO model yÃ¼klenirken hata oluÅŸtu: {e}")
#         return None
# 
# # --- Ana Uygulama ---
# st.set_page_config(layout="wide")
# st.title("YOLO v11 ÃœrÃ¼n Kategori Tahmini (Streamlit)")
# 
# st.sidebar.header("/content/drive/MyDrive/Prediction")
# uploaded_file = st.sidebar.file_uploader(
#     "LÃ¼tfen bir video dosyasÄ± (.mp4, .avi vb.) yÃ¼kleyin",
#     type=['mp4', 'avi', 'mov']
# )
# 
# if uploaded_file is not None:
#     model = load_yolo_model(MODEL_PATH)
#     if model is None:
#         st.stop()
# 
#     st.sidebar.success(f"YOLO11s modeli yÃ¼klendi. {model.model.yaml.get('nc', 'Bilinmeyen')} kategori hedefliyor.")
# 
#     with tempfile.NamedTemporaryFile(delete=False) as tfile:
#         tfile.write(uploaded_file.getbuffer())
#         temp_video_path = tfile.name
# 
#     cap = cv2.VideoCapture(temp_video_path)
#     video_placeholder = st.empty()
#     status_placeholder = st.sidebar.empty()
#     status_placeholder.info("Video kareleri iÅŸleniyor ve tahmin yapÄ±lÄ±yor...")
# 
#     frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     progress_bar = st.progress(0)
#     current_frame = 0
# 
#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break
# 
#         # YOLO Tahmini
#         results = model.predict(frame, verbose=False)
#         result_frame = results[0].plot()
# 
#         rgb_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
#         video_placeholder.image(rgb_frame, channels="RGB", use_column_width=True)
# 
#         current_frame += 1
#         progress_bar.progress(min(int(current_frame / frame_count * 100), 100))
# 
#     cap.release()
#     status_placeholder.success("âœ… Video iÅŸleme tamamlandÄ±.")
# 
#     os.remove(temp_video_path)
#     video_placeholder.empty()
# 
# else:
#     st.info("LÃ¼tfen Streamlit arayÃ¼zÃ¼ hazÄ±r olduÄŸunda sol menÃ¼den bir video yÃ¼kleyin.")

# Streamlit ve video iÅŸleme kÃ¼tÃ¼phaneleri
!pip install streamlit opencv-python numpy

# Ultralytics (Zaten yÃ¼klÃ¼ olmalÄ±, yine de emin olalÄ±m)
!pip install ultralytics

# Streamlit uygulamasÄ±nÄ± dÄ±ÅŸarÄ±ya aÃ§mak iÃ§in pyngrok
!pip install pyngrok

from pyngrok import ngrok
import os

# --- A. MODEL YOLU AYARI (KENDÄ° YOLUNUZLA GÃœNCELLEYÄ°N) ---
# Ã–rneÄŸin:
MODEL_PATH = "runs/detect/train/weights/best.pt"
# --------------------------------------------------------

# Model dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edelim
if os.path.exists(MODEL_PATH):
    print(f"âœ… BaÅŸarÄ±lÄ±! Model aÄŸÄ±rlÄ±klarÄ± bu yolda bulundu: {MODEL_PATH}")
else:
    print(f"âŒ Hata: Model aÄŸÄ±rlÄ±k dosyasÄ± {MODEL_PATH} yolunda bulunamadÄ±. LÃ¼tfen yolu kontrol edin.")

# --- B. NGROK AUTH TOKEN AYARI (KENDÄ° TOKENINIZLA GÃœNCELLEYÄ°N) ---
# Token'Ä±nÄ±zÄ± buraya tÄ±rnak iÅŸaretleri iÃ§ine yapÄ±ÅŸtÄ±rÄ±n
NGROK_AUTH_TOKEN = "CPB5DSEKWBXVDK27PNBEATPSFULZSB3H"

try:
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
    print("âœ… ngrok Auth Token baÅŸarÄ±yla kuruldu.")
except Exception as e:
    print(f"âŒ ngrok Auth Token kurulumunda hata: {e}. Token'Ä± kontrol edin.")

# Bu hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n. Hem âœ… model hem de âœ… token mesajÄ±nÄ± gÃ¶rmelisiniz!

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import cv2
# import numpy as np
# import tempfile
# import os
# from ultralytics import YOLO
# 
# # Model yolunu ortam deÄŸiÅŸkeninden alÄ±yoruz (HÃ¼cre 4'te ayarlanacak)
# MODEL_PATH = os.environ.get("runs/detect/train/weights/best.pt", "best.pt")
# 
# # Model bir kez yÃ¼klenir ve Ã¶nbelleÄŸe alÄ±nÄ±r
# @st.cache_resource
# def load_yolo_model(path):
#     try:
#         model = YOLO(path)
#         return model
#     except Exception as e:
#         st.error(f"YOLO model yÃ¼klenirken hata oluÅŸtu: {e}")
#         return None
# 
# # --- Ana Uygulama ---
# st.set_page_config(layout="wide")
# st.title("YOLO v11 ÃœrÃ¼n Kategori Tahmini (Streamlit)")
# 
# st.sidebar.header("1. Video YÃ¼kleme")
# uploaded_file = st.sidebar.file_uploader(
#     "LÃ¼tfen bir video dosyasÄ± (.mp4, .avi vb.) yÃ¼kleyin",
#     type=['mp4', 'avi', 'mov']
# )
# 
# if uploaded_file is not None:
#     model = load_yolo_model(MODEL_PATH)
#     if model is None:
#         st.stop()
# 
#     st.sidebar.success(f"YOLO11s modeli yÃ¼klendi.")
# 
#     with tempfile.NamedTemporaryFile(delete=False) as tfile:
#         tfile.write(uploaded_file.getbuffer())
#         temp_video_path = tfile.name
# 
#     cap = cv2.VideoCapture(temp_video_path)
#     video_placeholder = st.empty()
#     status_placeholder = st.sidebar.empty()
#     status_placeholder.info("Video kareleri iÅŸleniyor ve tahmin yapÄ±lÄ±yor...")
# 
#     frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     progress_bar = st.progress(0)
#     current_frame = 0
# 
#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break
# 
#         # YOLO Tahmini
#         results = model.predict(frame, verbose=False)
#         result_frame = results[0].plot()
# 
#         rgb_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
#         video_placeholder.image(rgb_frame, channels="RGB", use_column_width=True)
# 
#         current_frame += 1
#         progress_bar.progress(min(int(current_frame / frame_count * 100), 100))
# 
#     cap.release()
#     status_placeholder.success("âœ… Video iÅŸleme tamamlandÄ±.")
# 
#     os.remove(temp_video_path)
#     video_placeholder.empty()
# 
# else:
#     st.info("LÃ¼tfen Streamlit arayÃ¼zÃ¼ hazÄ±r olduÄŸunda sol menÃ¼den bir video yÃ¼kleyin.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import cv2
# import numpy as np
# import tempfile
# import os
# from ultralytics import YOLO
# 
# # Model yolunu ortam deÄŸiÅŸkeninden alÄ±yoruz (HÃ¼cre 4'te ayarlanacak)
# MODEL_PATH = os.environ.get("YOLO_MODEL_PATH", "best.pt")
# 
# # Model bir kez yÃ¼klenir ve Ã¶nbelleÄŸe alÄ±nÄ±r
# @st.cache_resource
# def load_yolo_model(path):
#     try:
#         model = YOLO(path)
#         return model
#     except Exception as e:
#         st.error(f"YOLO model yÃ¼klenirken hata oluÅŸtu: {e}")
#         return None
# 
# # --- Ana Uygulama ---
# st.set_page_config(layout="wide")
# st.title("YOLO v11 ÃœrÃ¼n Kategori Tahmini (Streamlit)")
# 
# st.sidebar.header("1. Video YÃ¼kleme")
# uploaded_file = st.sidebar.file_uploader(
#     "LÃ¼tfen bir video dosyasÄ± (.mp4, .avi vb.) yÃ¼kleyin",
#     type=['mp4', 'avi', 'mov']
# )
# 
# if uploaded_file is not None:
#     model = load_yolo_model(MODEL_PATH)
#     if model is None:
#         st.stop()
# 
#     st.sidebar.success(f"YOLO11s modeli yÃ¼klendi.")
# 
#     with tempfile.NamedTemporaryFile(delete=False) as tfile:
#         tfile.write(uploaded_file.getbuffer())
#         temp_video_path = tfile.name
# 
#     cap = cv2.VideoCapture(temp_video_path)
#     video_placeholder = st.empty()
#     status_placeholder = st.sidebar.empty()
#     status_placeholder.info("Video kareleri iÅŸleniyor ve tahmin yapÄ±lÄ±yor...")
# 
#     frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     progress_bar = st.progress(0)
#     current_frame = 0
# 
#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break
# 
#         # YOLO Tahmini
#         results = model.predict(frame, verbose=False)
#         result_frame = results[0].plot()
# 
#         rgb_frame = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
#         video_placeholder.image(rgb_frame, channels="RGB", use_column_width=True)
# 
#         current_frame += 1
#         progress_bar.progress(min(int(current_frame / frame_count * 100), 100))
# 
#     cap.release()
#     status_placeholder.success("âœ… Video iÅŸleme tamamlandÄ±.")
# 
#     os.remove(temp_video_path)
#     video_placeholder.empty()
# 
# else:
#     st.info("LÃ¼tfen Streamlit arayÃ¼zÃ¼ hazÄ±r olduÄŸunda sol menÃ¼den bir video yÃ¼kleyin.")

from pyngrok import ngrok
import os
import time
import subprocess
from google.colab import userdata # Import userdata

# ngrok kÃ¼tÃ¼phanesi 2. adÄ±mda zaten yÃ¼klenmiÅŸti

# 1. MODEL_PATH'i Ortam DeÄŸiÅŸkeni Olarak Ayarlama
# 2. HÃ¼creden gelen deÄŸiÅŸkeni kullanÄ±yoruz
os.environ["YOLO_MODEL_PATH"] = MODEL_PATH

# 2. ngrok TÃ¼nelini OluÅŸturma
ngrok.kill() # Ã–nceki tÃ¼m ngrok tÃ¼nellerini kapat
PORT = 8501

try:
    # Retrieve NGROK_AUTH_TOKEN from Colab secrets
    NGROK_AUTH_TOKEN = userdata.get('34xckhVkwAnzFOhSKnAOtLZKR9q_4fpAUiZTY45NfD78aTxfb')
    if not NGROK_AUTH_TOKEN:
        raise ValueError("NGROK_AUTH_TOKEN not found in Colab secrets.")

    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
    public_url = ngrok.connect(PORT, proto="http")
    print(f"ðŸš€ Streamlit uygulamanÄ±z yayÄ±nda! LÃ¼tfen aÅŸaÄŸÄ±daki linke TIKLAYINIZ:")
    print(f"URL: {public_url}")
    print("-" * 50)
except Exception as e:
    print(f"âŒ ngrok tÃ¼neli oluÅŸturulurken kritik hata oluÅŸtu: {e}")
    # Do not raise the exception to allow the notebook to continue
    # raise

# 3. Streamlit UygulamasÄ±nÄ± BaÅŸlatma
print("Streamlit uygulamasÄ±nÄ± baÅŸlatÄ±yor...")

# Komutu arka planda Ã§alÄ±ÅŸtÄ±rÄ±yoruz
command = f"streamlit run app.py --server.port {PORT} --server.headless true"
p = subprocess.Popen(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# UygulamanÄ±n baÅŸlamasÄ± iÃ§in kÄ±sa bir sÃ¼re bekleyelim
time.sleep(5)

print("Streamlit uygulamasÄ±nÄ±n arka plan iÅŸlemi baÅŸlatÄ±ldÄ±.")
print("LÃ¼tfen yukarÄ±daki URL'yi kontrol edin.")

from pyngrok import ngrok
import os
import time
import subprocess

# Model yolunun daha Ã¶nce belirlenmiÅŸ olmasÄ± gerekir.
os.environ["YOLO_MODEL_PATH"] = MODEL_PATH

# ngrok'u kapat ve Port'u ayarla
ngrok.kill()
PORT = 8501

try:
    # Token zaten kurulduÄŸunu varsayarak doÄŸrudan baÄŸlantÄ± kur
    public_url = ngrok.connect(PORT, proto="http")

    # --- BaÄŸlantÄ± BaÅŸarÄ±lÄ± ---
    print(f"ðŸš€ Streamlit uygulamanÄ±z yayÄ±nda! LÃ¼tfen aÅŸaÄŸÄ±daki linke TIKLAYINIZ:")
    print(f"URL: {public_url}")
    print("-" * 50)

    # Streamlit UygulamasÄ±nÄ± BaÅŸlatma (Arka planda)
    print("Streamlit uygulamasÄ±nÄ± baÅŸlatÄ±yor...")
    command = f"streamlit run app.py --server.port {PORT} --server.headless true"
    subprocess.Popen(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    time.sleep(5)
    print("Streamlit uygulamasÄ±nÄ±n arka plan iÅŸlemi baÅŸlatÄ±ldÄ±.")

except Exception as e:
    # --- BaÄŸlantÄ± BaÅŸarÄ±sÄ±z ---
    print(f"âŒ KRÄ°TÄ°K HATA: ngrok tÃ¼neli oluÅŸturulurken hata oluÅŸtu: {e}")
    print("NGROK_AUTH_TOKEN'Ä± doÄŸru kopyalayÄ±p kurduÄŸunuzdan emin olun ve bu hÃ¼creyi tekrar deneyin.")

